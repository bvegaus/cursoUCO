{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A diferencia del tipo de red usada en el ejercicio anterior, las redes neuronales convolucionales son conocidas por su gran éxito al trabajar sobre **imágenes**. \n",
    "\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "El objetivo de esta parte es tratar las imágenes obtenidas a partir del GC-IMS con este tipo de redes para clasificarlas entre las tres categorías existentes (EVOO/LOO/VOO), además de familiarizarnos con cada una de las capas que se pueden usar en este tipo de redes.\n",
    "</div>\n",
    "\n",
    "Varios aspectos a tener en cuenta:\n",
    "* Para un ordenador, una imagen es una matriz de datos, donde cada píxel está representado por uno o más valores:\n",
    "    * Si la matriz tiene un valor por píxel $\\rightarrow$ imagen en escala de grises\n",
    "    <img src=\"img/eight.gif\" alt=\"Drawing\" style=\"width: 200px;\"/>\n",
    "    * Si la matriz tiene tres valores por píxel $\\rightarrow$ imagen a color\n",
    "    <img src=\"img/Imagen12.png\" alt=\"Drawing\" style=\"width: 400;\"/>\n",
    "\n",
    "\n",
    "\n",
    "## 1. Conociendo los datos\n",
    "Recordemos que en el primer notebook hicimos una lectura de los datos y los guardamos en dos ficheros: **X.npy** e **Y.npy**. El primer paso consistirá en leer los datos a partir de estos dos ficheros\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.load(\"./data/huella_espectral/X.npy\")\n",
    "y = np.load(\"./data/huella_espectral/Y.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 1905, 3000)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 2.,\n",
       "       2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En resumen tenemos los siguientes datos.\n",
    "\n",
    "* **input** $\\rightarrow$ 28 muestras de aceite\n",
    "    * Cada muestra tiene 1 valor por píxel (imágenes en escala de grises)\n",
    "    * Cada imagen queda represntada por una matriz de tamaño $1905\\times 3000$\n",
    "* **target** $\\rightarrow$ 28 enteros indicando la clase "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
